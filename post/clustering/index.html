<!DOCTYPE html>
<html  dir="ltr" lang="en" data-theme=""><head>
    <title> Rikesh Lad | K-Means Clustering (Python) </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.82.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="K-Means Clustering performed on the Iris dataset.">
    
    
    
    
    <link rel="stylesheet"
        href="/rikeshlad2709.github.io/css/main.min.f79a5de55310cc058fc81804d033ddb955937d778bd533d9ea05b1c798501013.css"
        integrity="sha256-95pd5VMQzAWPyBgE0DPduVWTfXeL1TPZ6gWxx5hQEBM="
        crossorigin="anonymous"
        type="text/css">
    
    
    <link rel="stylesheet"
        href="/rikeshlad2709.github.io/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css"
        integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS&#43;yuWSR4="
        crossorigin="anonymous"
        type="text/css">
    
    <link rel="stylesheet" 
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" 
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" 
    crossorigin="anonymous" />

    
    <link rel="shortcut icon" href="/rikeshlad2709.github.io/favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="/rikeshlad2709.github.io/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/rikeshlad2709.github.io/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/rikeshlad2709.github.io/favicons/favicon-16x16.png">

    <link rel="canonical" href="rikeshlad2709.github.io/post/clustering/">

    
    
    
    
    <script type="text/javascript"
            src="/rikeshlad2709.github.io/js/anatole-header.min.0c05c0a90d28c968a1cad4fb31abd0b8e1264e788ccefed022ae1d3b6f627514.js"
            integrity="sha256-DAXAqQ0oyWihytT7MavQuOEmTniMzv7QIq4dO29idRQ="
            crossorigin="anonymous"></script>


    
        
        
        <script type="text/javascript"
                src="/rikeshlad2709.github.io/js/anatole-theme-switcher.min.7fd87181cdd7e8413aa64b6867bb32f3a8dc242e684fc7d5bbb9f600dbc2b6eb.js"
                integrity="sha256-f9hxgc3X6EE6pktoZ7sy86jcJC5oT8fVu7n2ANvCtus="
                crossorigin="anonymous"></script>
    
    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="rikeshlad2709.github.io/images/site-feature-image.png"/>

<meta name="twitter:title" content="K-Means Clustering (Python)"/>
<meta name="twitter:description" content="K-Means Clustering performed on the Iris dataset."/>


    

</head>
<body><div class="sidebar animated fadeInDown ">
    <div class="logo-title">
        <div class="title">
            <img src="/rikeshlad2709.github.io/images/DeerLogo.jpg" alt="profile picture">
            <h3 title=""><a href="/">Rikesh Lad</a></h3>
            <div class="description">
                <p>Data Scientist | Data Analyst <br> These projects are to showcase some of my knowledge of Data Science methods and techniques that are difficult for me to demonstrate from professional experience. It <strong>should not</strong> be considered an exhaustive list.</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="https://www.linkedin.com/in/rikesh-lad-2709/" rel="me" aria-label="Linkedin">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://github.com/rikeshlad2709" rel="me" aria-label="GitHub">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="mailto:rikeshlad2709@gmail.com" rel="me" aria-label="e-mail">
                    <i class="fas fa-envelope fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        
        <div class="by_farbox"> Rikesh Lad  2021 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  animated fadeInDown ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="rikeshlad2709.github.io/"
                        
                   title="">Home</a></li>
        
            
            <li><a 
                   href="rikeshlad2709.github.io/post/"
                        
                   title="">Projects</a></li>
        
            
            <li><a 
                   href="rikeshlad2709.github.io/about/"
                        
                   title="">CV / Resume</a></li>
        
        
            
                <li><a href="rikeshlad2709.github.io/"
                       title="EN">EN</a>
                </li>
            
                <li><a href="rikeshlad2709.github.io/ar/"
                       title=""></a>
                </li>
            
        
        
            <li class="theme-switch-item">
                <a class="theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">
    <div class="post  animated fadeInDown ">
        <div class="post-content">
            
            <img class="post-thumbnail" src="/rikeshlad2709.github.io/images/clustering_thumbnail.jpg" alt="Thumbnail image">
            
            <div class="post-title">
                <h3>K-Means Clustering (Python)</h3>
                
                    <div class="info">
                        <em class="fas fa-calendar-day"></em>
                        <span class="date"> 
                                                23/5/2021
                                           </span>
                        <em class="fas fa-stopwatch"></em>
                        <span class="reading-time">5-minute read</span>
                    </div>
                
            </div>

            <p>I&rsquo;ll be using a K-Means clustering algorithm to group a sample of data. Input features will be rescaled to ensure all variables are treated as if they have the same weight. Number of clusters will be selected using the Elbow method. This will be done algorithmically by using the line from the inertia of the first cluster to the last, with the number of clusters selected by the furthest distance to the line. Once a K-Means model has been selected, I&rsquo;ll be using Principal Component Analysis to reduce the dimensionality of my input data to 2 so that I can display the results of my clustering model graphically, in a way that is more visually clear.</p>
<p>The data being used comes from the Iris dataset. The Iris dataset consists of 4 input variables that describe the length and width of the flowers' sepals and petals, and 1 target variable that is the species of the flower. The dataset contains 150 records.</p>
<table>
<thead>
<tr>
<th style="text-align:center">  Id  </th>
<th style="text-align:center">  SepalLengthCm  </th>
<th style="text-align:center">  SepalWidthCm  </th>
<th style="text-align:center">  PetalLengthCm  </th>
<th style="text-align:center">  PetalWidthCm  </th>
<th style="text-align:center">  Species  </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">5.1</td>
<td style="text-align:center">3.5</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">Iris-setosa</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">4.9</td>
<td style="text-align:center">3.0</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">Iris-setosa</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">4.7</td>
<td style="text-align:center">3.2</td>
<td style="text-align:center">1.3</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">Iris-setosa</td>
</tr>
<tr>
<td style="text-align:center"><strong>&hellip;</strong></td>
<td style="text-align:center"><strong>&hellip;</strong></td>
<td style="text-align:center"><strong>&hellip;</strong></td>
<td style="text-align:center"><strong>&hellip;</strong></td>
<td style="text-align:center"><strong>&hellip;</strong></td>
<td style="text-align:center"><strong>&hellip;</strong></td>
</tr>
</tbody>
</table>
<p>The dataset is available here: <a href="https://archive.ics.uci.edu/ml/datasets/iris">https://archive.ics.uci.edu/ml/datasets/iris</a>.</p>
<h3 id="summary">Summary</h3>
<p>It can be seen in the graph that 2 of the species had very similar characteristics. More data might be needed to more easily different 2 species of similar sized petals and sepals. Data such as RBG values for the petal colour may help.</p>
<p>One of the key issues with K-Means clustering can be clearly seen in the empty space between clusters 2 &amp; 3. New data that falls into this empty region likely shouldn&rsquo;t be classified into either cluster, but K-Means does not consider noise.</p>
<p><img src="../images/Clusters.jpg" alt="K-Means Clusters"></p>
<p>Most of the records were classified into the same cluster.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Flower  </th>
<th style="text-align:right">  Cluster 0</th>
<th style="text-align:right">  Cluster 1</th>
<th style="text-align:right">  Cluster 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Setosa</td>
<td style="text-align:right">0</td>
<td style="text-align:right">50</td>
<td style="text-align:right">0</td>
</tr>
<tr>
<td style="text-align:left">Versicolor</td>
<td style="text-align:right">5</td>
<td style="text-align:right">0</td>
<td style="text-align:right">45</td>
</tr>
<tr>
<td style="text-align:left">Virginica</td>
<td style="text-align:right">0</td>
<td style="text-align:right">0</td>
<td style="text-align:right">50</td>
</tr>
</tbody>
</table>
<h3 id="normalisation">Normalisation</h3>
<p>It is best to normalise this dataset before applying a clustering algorithm. Variables in this dataset will have naturally different scales which will cause some variables to have heavier weighting in the clustering algorithm. To ensure that all variables are given the same weight in influence.</p>
<p>There can be some circumstances where normalising is not suitable, such as when dealing with coordinate variables like latitude and longitude.</p>
<p>In this case I&rsquo;ll being using normalize from the Scikit-Learn library to rescale the variables to unit norm. This will place all variable on a scale between 0 and 1.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
</code></pre></div><h3 id="k-means-clustering">K-Means Clustering</h3>
<p>In the following python code \(X\) will denote a NumPy matrix array (150, 4) for input variables.</p>
<p>K-Means clustering algorithm seeks to split the data into a given number of clusters by minimizing the within-cluster variance. The resulting model can classify new data into modelled clusters by selecting the closest centroid for any given new data, which does give it predictive power. By dealing with new data in this way, the K-Means model essentially splits your entire vector-space into regions associated to each cluster. This means that the K-Means method cannot account for noise in your data and will be influenced by anomalous data points.</p>
<p>To select an appropriate number of clusters for K-Means, I&rsquo;ll be using the elbow method with K-Means inertia. First define a simple function to calculate the inertia of a fitted K-Means model with a given number of clusters.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="k">def</span> <span class="nf">inertia_value</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="c1"># Fit K-Means model for given k</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Return inertia</span>
    <span class="k">return</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span>
</code></pre></div><p>And then calculate the inertia for a range of cluster numbers.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Minimum k</span>
<span class="n">k_start</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Maximum k</span>
<span class="n">k_max</span> <span class="o">=</span> <span class="mi">30</span>
<span class="c1"># List of all inertia values</span>
<span class="n">inertia_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">inertia_value</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k_start</span><span class="p">,</span> <span class="n">k_max</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</code></pre></div><p>Results can then be plotted.</p>
<p><img src="../images/ElbowMethod.jpg" alt="Plot of Inertia"></p>
<p>The appropriate cluster number could be eyeballed at this points, but I prefer mathematical selection method. A line can be plotted from the first inertia value to the last, and then the optimal cluster number can be selected as the furthest point from the line. For a straight line equation \(y = ax + b\), the gradient and intercept can be calculated simply. For a point \((x_0,y_0)\) and straight line \(y = ax + b\), the shortest distance is given by</p>
<p>$$
\frac{|ax_0 + y_0 + b|}{\sqrt{a^{2} + 1}}
$$</p>
<p>Hence the following function can be written to select the appropriate cluster number.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">select_k</span><span class="p">(</span><span class="n">k_start</span><span class="p">,</span> <span class="n">k_max</span><span class="p">,</span> <span class="n">inertia_list</span><span class="p">):</span>
    <span class="c1"># Straight line parameters</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">inertia_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">inertia_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">k_max</span> <span class="o">-</span> <span class="n">k_start</span><span class="p">)</span>
    <span class="n">const</span> <span class="o">=</span> <span class="n">inertia_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">k_start</span>
    <span class="c1"># List for all distances</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Loop through list of inertias</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inertia_list</span><span class="p">)):</span>
        <span class="c1"># Calculate and append distance</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="n">k_start</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">-</span> <span class="n">inertia_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">const</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">grad</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># Return k associated with largest distance</span>
    <span class="k">return</span> <span class="n">k_start</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
</code></pre></div><p>When run on the data, this function selects 3 and the appropriate number of clusters. Interestingly, the selected number of clusters is actually 2 when using a lower maximum. As it&rsquo;s known that there are 3 species in the dataset, it suggests 2 of the flower species have similar characteristics.</p>
<h3 id="visualize">Visualize</h3>
<h4 id="principal-component-analysis">Principal Component Analysis</h4>
<p>I&rsquo;ll be using principal components to reduce the dimensionailty of the dataset to 2. Principal Component Analysis (PCA) will give vectors that try to preserve the variance in the data. The principal components will be derived using PCA from Scikit-Learn library.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pComponents</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div><h4 id="results">Results</h4>
<p>Most of the records were classified into the same cluster.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Flower  </th>
<th style="text-align:right">  Cluster 0</th>
<th style="text-align:right">  Cluster 1</th>
<th style="text-align:right">  Cluster 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Setosa</td>
<td style="text-align:right">0</td>
<td style="text-align:right">50</td>
<td style="text-align:right">0</td>
</tr>
<tr>
<td style="text-align:left">Versicolor</td>
<td style="text-align:right">5</td>
<td style="text-align:right">0</td>
<td style="text-align:right">45</td>
</tr>
<tr>
<td style="text-align:left">Virginica</td>
<td style="text-align:right">0</td>
<td style="text-align:right">0</td>
<td style="text-align:right">50</td>
</tr>
</tbody>
</table>
<p>It can be seen in the graph that 2 of the species had very similar characteristics. More data might be needed to more easily different 2 species of similar sized petals and sepals. Data such as RBG values for the petal colour may help.</p>
<p>One of the key issues with K-Means clustering can be clearly seen in the empty space between clusters 2 &amp; 3. New data that falls into this empty region likely shouldn&rsquo;t be classified into either cluster, but K-Means does not consider noise.</p>
<p><img src="../images/Clusters.jpg" alt="K-Means Clusters"></p>
</div>
        <div class="post-footer">
            <div class="info">
                
                <span class="separator"><a class="tag" href="/rikeshlad2709.github.io/tags/kmeans/">kmeans</a><a class="tag" href="/rikeshlad2709.github.io/tags/clustering/">clustering</a><a class="tag" href="/rikeshlad2709.github.io/tags/python/">python</a></span>
            </div>
        </div>

        
    </div>


        </div>
    </div>
</div>

<script type="text/javascript"
        src="/rikeshlad2709.github.io/js/medium-zoom.min.83cb1dd5fea8d42d87d1e601a07faa73089ad0ef9ccfe5daf6041289ebcc4e46.js"
        integrity="sha256-g8sd1f6o1C2H0eYBoH&#43;qcwia0O&#43;cz&#43;Xa9gQSievMTkY="
        crossorigin="anonymous"></script><link rel="stylesheet"
              href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css"
              integrity="sha384-t5CR&#43;zwDAROtph0PXGte6ia8heboACF9R5l/DiY&#43;WZ3P2lxNgvJkQk5n7GPvLMYw"
              crossorigin="anonymous"><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js"
                integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8&#43;w2LAIftJEULZABrF9PPFv&#43;tVkH"
                crossorigin="anonymous"></script><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js"
                integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB&#43;w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v"
                crossorigin="anonymous"
                onload="renderMathInElement(document.body);"></script></body>

</html>
